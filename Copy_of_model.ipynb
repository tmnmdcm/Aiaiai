{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Y2nY9SW0InpU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Define paths\n",
    "drive_path = \"\"\n",
    "train_image_path = drive_path + \"dataset/train/images\"\n",
    "test_image_path = drive_path + \"dataset/test/images\"\n",
    "train_label_path = drive_path + \"dataset/train/labels\"\n",
    "test_label_path = drive_path + \"dataset/test/labels\""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qIZlRAEQInpW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "image_path = drive_path + \"dataset/train/images/DJI_0004_03_07.png\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "image_shape = image.shape\n",
    "\n",
    "# image_height, image_width, num_channels = image_shape\n",
    "\n",
    "image_height, image_width, num_channels = (256, 256, 3)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "u50YEmiWInpW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class_names = [\"Damage/Dirt\", \"No Damage/Dirt\"]\n",
    "\n",
    "train_limit = 1000\n",
    "test_limit = 300\n",
    "\n",
    "# if not train_limit:\n",
    "n_train = min(len(os.listdir(train_image_path)), train_limit)\n",
    "n_test = min(len(os.listdir(test_image_path)), test_limit)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "EVj8855zInpW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# data_augmentation = ImageDataGenerator(\n",
    "#     rotation_range=10,  # Rotate images randomly by up to 10 degrees\n",
    "#     width_shift_range=0.1,  # Shift images horizontally by up to 10% of the width\n",
    "#     height_shift_range=0.1,  # Shift images vertically by up to 10% of the height\n",
    "#     horizontal_flip=True,  # Flip images horizontally\n",
    "#     vertical_flip=False  # Do not flip images vertically\n",
    "# )\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.1),\n",
    "  layers.RandomTranslation(0.1, 0.1)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def _generate_batch_train_images(start_index, end_index):\n",
    "    n = end_index - start_index + 1\n",
    "    train_images = np.zeros(n, dtype=(np.float32, (image_height, image_width, num_channels)))\n",
    "    train_labels = np.zeros(n)\n",
    "\n",
    "\n",
    "    # Add train images and labels into array\n",
    "    for idx, image_path in enumerate(os.listdir(train_image_path)[:train_limit][start_index:end_index]):\n",
    "        image = cv2.imread(os.path.join(train_image_path, image_path))\n",
    "        image = cv2.resize(image, (image_height, image_width))\n",
    "        image = image / 255.0  # Scale pixel values to [0, 1]\n",
    "        train_images[idx] = image\n",
    "\n",
    "        label_path = image_path[:-3] + \"txt\"\n",
    "\n",
    "        with open(os.path.join(train_label_path, label_path), 'r') as f:\n",
    "            train_labels[idx] = (f.read().strip() == class_names[1])\n",
    "\n",
    "    return data_augmentation(train_images), train_labels\n",
    "\n",
    "def _generate_batch_test_images(start_index, end_index):\n",
    "    n = end_index - start_index + 1\n",
    "    test_images = np.zeros(n, dtype=(np.float32, (image_height, image_width, num_channels)))\n",
    "    test_labels = np.zeros(n)\n",
    "\n",
    "\n",
    "    # Add train images and labels into array\n",
    "    for idx, image_path in enumerate(os.listdir(test_image_path)[:test_limit][start_index:end_index]):\n",
    "        image = cv2.imread(os.path.join(test_image_path, image_path))\n",
    "        image = cv2.resize(image, (image_height, image_width))\n",
    "        image = image / 255.0  # Scale pixel values to [0, 1]\n",
    "        test_images[idx] = image\n",
    "\n",
    "        label_path = image_path[:-3] + \"txt\"\n",
    "\n",
    "        with open(os.path.join(test_label_path, label_path), 'r') as f:\n",
    "            test_labels[idx] = (f.read().strip() == class_names[1])\n",
    "\n",
    "    return test_images, test_labels"
   ],
   "metadata": {
    "id": "C5G5AVUGbc1d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Batch generator for training images\n",
    "\n",
    "def batch_train(batch_size):\n",
    "    num_samples = n_train\n",
    "\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "    for start_index in range(0, num_samples, batch_size):\n",
    "        end_index = min(start_index + batch_size, num_samples)\n",
    "        # batch_indices = indices[start_index:end_index]\n",
    "\n",
    "        yield _generate_batch_train_images(start_index, end_index)\n",
    "\n",
    "\n",
    "def batch_test(batch_size):\n",
    "    num_samples = n_test\n",
    "\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "    for start_index in range(0, num_samples, batch_size):\n",
    "        end_index = min(start_index + batch_size, num_samples)\n",
    "        # batch_indices = indices[start_index:end_index]\n",
    "\n",
    "        yield _generate_batch_test_images(start_index, end_index)\n",
    "\n"
   ],
   "metadata": {
    "id": "jS9MsVMIahR-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# 0 -> No damage\n",
    "# 1 -> Dirt/Damage"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QUU5pto6InpX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu', input_shape=(image_width, image_height, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # Use a single unit with sigmoid activation for binary classification\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "aAEU2x88InpY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class EarlyStopping(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    '''\n",
    "    Stops training when 95% accuracy is reached\n",
    "    '''\n",
    "    # Get the current accuracy and check if it is above 95%\n",
    "    if(logs.get('accuracy') > 0.95):\n",
    "\n",
    "      # Stop training if condition is met\n",
    "      print(\"\\nThreshold reached. Stopping training...\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Let's instantiate our ES class\n",
    "early_stopping = EarlyStopping()"
   ],
   "metadata": {
    "id": "f8ZCZ4xwUGjx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "class A:\n",
    "    def gen(self):\n",
    "        yield 1\n",
    "\n",
    "class custom_generator(A):\n",
    "  def __init__(self, generator, batch_size):\n",
    "    self.generator = generator\n",
    "    self.batch_size = batch_size\n",
    "    self.generated = generator(batch_size)\n",
    "\n",
    "  def __iter__(self):\n",
    "    return self\n",
    "\n",
    "  def __next__(self):\n",
    "    try:\n",
    "      next_value = next(self.generated)\n",
    "    except StopIteration:\n",
    "      self.generated = self.generator(self.batch_size)\n",
    "      next_value = next(self.generated)\n",
    "\n",
    "    return next_value\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "X6YMK7uyInpY",
    "outputId": "db3c642d-c783-42ac-b7fc-498ac81f8055",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 8/31 [======>.......................] - ETA: 2:12 - loss: 0.7049 - accuracy: 0.5758 - precision: 0.5625 - recall: 1.0000"
     ]
    }
   ],
   "source": [
    "train_batch_generator = custom_generator(batch_train, batch_size)\n",
    "test_batch_generator = custom_generator(batch_test, batch_size)\n",
    "\n",
    "\n",
    "history = model.fit(train_batch_generator, epochs=150,\n",
    "                    validation_data=test_batch_generator,\n",
    "                    steps_per_epoch=n_train // batch_size,\n",
    "                    validation_steps=n_test // batch_size,\n",
    "                    callbacks=[early_stopping])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot metrics\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.plot(history.history['val_precision'], label='val_precision')\n",
    "plt.plot(history.history['val_recall'], label='val_recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7P6iyUVSInpZ",
    "outputId": "8294892e-94e8-4740-a10a-e990af6443ac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc, test_precision, test_recall = model.evaluate(test_images, test_labels, verbose=2)\n",
    "test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "print(\"test accuracy:\", test_acc)\n",
    "print(\"test precision:\", test_precision)\n",
    "print(\"test recall:\", test_recall)\n",
    "print(\"test F1-score:\", test_f1_score)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "h9q7iwO7InpZ",
    "outputId": "faa90b40-0941-4f06-d953-4f2fa001ccaa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "d_NQ_1zXFTHb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}